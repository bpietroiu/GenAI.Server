# GenAI.Server
OnnxRuntime.GenAI based OpenAI Api compatible Server 

My toy project fot hosting and serving OnnxRuntime.GenAI models.

Includes a Jinja port from HF Jinja JS so the chat prompt template is taken from tokenizer.config

Includes a minimal API implementation with /models and chat/completions endpoints, not auth yet

